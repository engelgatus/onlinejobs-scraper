name: OnlineJobs.ph Scraper

on:
  schedule:
    # Run twice daily: 8 AM and 8 PM UTC
    - cron: '0 8,20 * * *'
  workflow_dispatch:  # Allow manual trigger
  
env:
  PYTHON_VERSION: '3.11'

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data directory
      run: mkdir -p data
    
    - name: Cache database
      uses: actions/cache@v4
      with:
        path: data/jobs.db
        key: jobs-db-${{ github.run_id }}
        restore-keys: |
          jobs-db-
    
    - name: Run scraper
      env:
        DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        GITHUB_ACTIONS: 'true'
      run: |
        python main.py --days 5
    
    - name: Show database stats
      run: |
        python main.py --stats
    
    # Optional: Upload database as artifact for debugging
    - name: Upload database artifact
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: jobs-database
        path: data/jobs.db
        retention-days: 7
